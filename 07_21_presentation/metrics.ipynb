{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple metrics\n",
    "- Weighted average\n",
    "- Median\n",
    "- Variance\n",
    "- Annual root mean squared error (RMSE)\n",
    "\n",
    "Outliers are always removed, VOLL = 9e06, large impact on metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2012\n",
      "Empirical weighted Average: 28.201155410541354\n",
      "Synthetic weighted Average: 31.347298925823317\n",
      "Average Difference: -3.1461435152819632\n",
      "\n",
      "Empirical Median: 22.98\n",
      "Synthetic Median: 29.324429\n",
      "Median Difference: -6.344428999999998\n",
      "\n",
      "Empirical Variance: 279.8241386797161\n",
      "Synthetic Variance: 124.95947760710827\n",
      "Variance Difference: 154.86466107260782\n",
      "\n",
      "RMSE: 15.472198551959897\n",
      "\n",
      "Year: 2013\n",
      "Empirical weighted Average: 33.36489334219304\n",
      "Synthetic weighted Average: 37.08112741639506\n",
      "Average Difference: -3.7162340742020206\n",
      "\n",
      "Empirical Median: 29.53\n",
      "Synthetic Median: 33.418197134805\n",
      "Median Difference: -3.8881971348049973\n",
      "\n",
      "Empirical Variance: 119.27554649130352\n",
      "Synthetic Variance: 153.38603407272808\n",
      "Variance Difference: -34.110487581424564\n",
      "\n",
      "RMSE: 11.155609186420614\n",
      "\n",
      "Year: 2014\n",
      "Empirical weighted Average: 39.3503377947257\n",
      "Synthetic weighted Average: 39.94545432178903\n",
      "Average Difference: -0.5951165270633325\n",
      "\n",
      "Empirical Median: 33.02\n",
      "Synthetic Median: 33.833085\n",
      "Median Difference: -0.8130849999999938\n",
      "\n",
      "Empirical Variance: 356.3280817602688\n",
      "Synthetic Variance: 243.51151781546625\n",
      "Variance Difference: 112.81656394480254\n",
      "\n",
      "RMSE: 15.602299982281322\n",
      "\n",
      "Year: 2015\n",
      "Empirical weighted Average: 26.14028583155909\n",
      "Synthetic weighted Average: 26.623590219142237\n",
      "Average Difference: -0.4833043875831464\n",
      "\n",
      "Empirical Median: 21.64\n",
      "Synthetic Median: 24.132937951275\n",
      "Median Difference: -2.4929379512749996\n",
      "\n",
      "Empirical Variance: 174.15483879050447\n",
      "Synthetic Variance: 121.77147428454853\n",
      "Variance Difference: 52.38336450595594\n",
      "\n",
      "RMSE: 11.541308979202086\n",
      "\n",
      "Year: 2016\n",
      "Empirical weighted Average: 23.849253350343584\n",
      "Synthetic weighted Average: 26.3026980548773\n",
      "Average Difference: -2.453444704533716\n",
      "\n",
      "Empirical Median: 19.62\n",
      "Synthetic Median: 23.169365\n",
      "Median Difference: -3.549364999999998\n",
      "\n",
      "Empirical Variance: 130.62569615583524\n",
      "Synthetic Variance: 165.34039752140262\n",
      "Variance Difference: -34.71470136556738\n",
      "\n",
      "RMSE: 10.64737555400209\n",
      "\n",
      "Year: 2017\n",
      "Empirical weighted Average: 25.80027214002061\n",
      "Synthetic weighted Average: 30.821761047145138\n",
      "Average Difference: -5.021488907124528\n",
      "\n",
      "Empirical Median: 22.03\n",
      "Synthetic Median: 27.899996\n",
      "Median Difference: -5.869996\n",
      "\n",
      "Empirical Variance: 84.8689584144488\n",
      "Synthetic Variance: 185.20574077955735\n",
      "Variance Difference: -100.33678236510855\n",
      "\n",
      "RMSE: 11.93094230246787\n",
      "\n",
      "Year: 2018\n",
      "Empirical weighted Average: 33.9331750452113\n",
      "Synthetic weighted Average: 34.43451261555474\n",
      "Average Difference: -0.5013375703434377\n",
      "\n",
      "Empirical Median: 24.56\n",
      "Synthetic Median: 31.239179\n",
      "Median Difference: -6.679179000000001\n",
      "\n",
      "Empirical Variance: 1355.8592479286422\n",
      "Synthetic Variance: 278.4077132497222\n",
      "Variance Difference: 1077.4515346789199\n",
      "\n",
      "RMSE: 28.170227942083024\n",
      "\n",
      "Year: 2019\n",
      "Empirical weighted Average: 38.5744363858958\n",
      "Synthetic weighted Average: 27.10716528149\n",
      "Average Difference: 11.4672711044058\n",
      "\n",
      "Empirical Median: 20.54\n",
      "Synthetic Median: 23.871221\n",
      "Median Difference: -3.3312209999999993\n",
      "\n",
      "Empirical Variance: 7774.852126694856\n",
      "Synthetic Variance: 200.41999400452974\n",
      "Variance Difference: 7574.432132690326\n",
      "\n",
      "RMSE: 77.5505682544948\n",
      "\n",
      "Year: 2020\n",
      "Empirical weighted Average: 22.41215882343414\n",
      "Synthetic weighted Average: 21.418404452544184\n",
      "Average Difference: 0.9937543708899561\n",
      "\n",
      "Empirical Median: 17.52\n",
      "Synthetic Median: 19.74302\n",
      "Median Difference: -2.2230200000000018\n",
      "\n",
      "Empirical Variance: 215.7119482174577\n",
      "Synthetic Variance: 144.80289033975242\n",
      "Variance Difference: 70.90905787770527\n",
      "\n",
      "RMSE: 13.41493735178588\n",
      "\n",
      "Year: 2021\n",
      "Empirical weighted Average: 147.5625902537409\n",
      "Synthetic weighted Average: 41.857298562726264\n",
      "Average Difference: 105.70529169101462\n",
      "\n",
      "Empirical Median: 27.94\n",
      "Synthetic Median: 34.22604\n",
      "Median Difference: -6.286039999999996\n",
      "\n",
      "Empirical Variance: 662513.4981220281\n",
      "Synthetic Variance: 597.2860176935443\n",
      "Variance Difference: 661916.2121043345\n",
      "\n",
      "RMSE: 742.3484033625604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of years\n",
    "years = range(2012, 2022)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the years\n",
    "for year in years:\n",
    "    # Read the empirical prices\n",
    "    empirical_prices = pd.read_csv(f\"{year}prices_emp.csv\")\n",
    "    \n",
    "    # Read the synthetic prices and add a Time_Index column\n",
    "    synthetic_prices = pd.read_csv(f\"{year}prices.csv\")\n",
    "    synthetic_prices['Time_Index'] = synthetic_prices.index + 1\n",
    "    \n",
    "    # Read the weights\n",
    "    weights = pd.read_csv(f\"{year}Load_data.csv\")\n",
    "    \n",
    "    # Merge the data based on Time_Index\n",
    "    merged_data = empirical_prices.merge(synthetic_prices, on='Time_Index').merge(weights, on='Time_Index')\n",
    "    \n",
    "    # Exclude the n highest prices for empirical and synthetic prices\n",
    "    n = 15\n",
    "    empirical_prices_excluded = empirical_prices.nsmallest(len(empirical_prices) - n, 'Price')\n",
    "    synthetic_prices_excluded = synthetic_prices.nsmallest(len(synthetic_prices) - n, '1')\n",
    "    \n",
    "    # Calculate the weighted average for empirical prices (excluding the highest prices)\n",
    "    empirical_weighted_avg = (merged_data.loc[merged_data.index.isin(empirical_prices_excluded.index), 'Price'] * merged_data.loc[merged_data.index.isin(empirical_prices_excluded.index), 'Load_MW_z1']).sum() / merged_data.loc[merged_data.index.isin(empirical_prices_excluded.index), 'Load_MW_z1'].sum()\n",
    "    \n",
    "    # Calculate the median for empirical prices (excluding the highest prices)\n",
    "    empirical_median = np.median(empirical_prices_excluded['Price'])\n",
    "    \n",
    "    # Calculate the variance for empirical prices (excluding the highest prices)\n",
    "    empirical_variance = empirical_prices_excluded['Price'].var()\n",
    "\n",
    "    # Calculate the weighted average for synthetic prices (excluding the highest prices)\n",
    "    synthetic_weighted_avg = (merged_data.loc[merged_data.index.isin(synthetic_prices_excluded.index), '1'] * merged_data.loc[merged_data.index.isin(synthetic_prices_excluded.index), 'Load_MW_z1']).sum() / merged_data.loc[merged_data.index.isin(synthetic_prices_excluded.index), 'Load_MW_z1'].sum()\n",
    "    \n",
    "    # Calculate the median for synthetic prices (excluding the highest prices)\n",
    "    synthetic_median = np.median(synthetic_prices_excluded['1'])\n",
    "\n",
    "    # Calculate the variance for synthetic prices (excluding the highest prices)\n",
    "    synthetic_variance = synthetic_prices_excluded['1'].var()\n",
    "    \n",
    "    # Calculate the difference between the weighted averages\n",
    "    weighted_avg_diff = empirical_weighted_avg - synthetic_weighted_avg\n",
    "    \n",
    "    # Calculate the difference between the medians\n",
    "    median_diff = empirical_median - synthetic_median\n",
    "\n",
    "    # Calculate the difference between the variances\n",
    "    variance_diff = empirical_variance - synthetic_variance\n",
    "\n",
    "    # Calculate the root mean squared error between the empirical and synthetic prices, excluding the highest prices\n",
    "    rmse = np.sqrt(((empirical_prices_excluded['Price'] - synthetic_prices_excluded['1']) ** 2).mean())\n",
    "    \n",
    "    # Print the results for the year\n",
    "    print(f\"Year: {year}\")\n",
    "    print(f\"Empirical weighted Average: {empirical_weighted_avg}\")\n",
    "    print(f\"Synthetic weighted Average: {synthetic_weighted_avg}\")\n",
    "    print(f\"Average Difference: {weighted_avg_diff}\\n\")\n",
    "    print(f\"Empirical Median: {empirical_median}\")\n",
    "    print(f\"Synthetic Median: {synthetic_median}\")\n",
    "    print(f\"Median Difference: {median_diff}\\n\")\n",
    "    print(f\"Empirical Variance: {empirical_variance}\")\n",
    "    print(f\"Synthetic Variance: {synthetic_variance}\")\n",
    "    print(f\"Variance Difference: {variance_diff}\\n\")\n",
    "    print(f\"RMSE: {rmse}\\n\")\n",
    "    \n",
    "    # Create a DataFrame for the current year's metrics\n",
    "    year_metrics = pd.DataFrame({'Year': [year],\n",
    "                                 'Empirical Average': [empirical_weighted_avg],\n",
    "                                 'Synthetic Average': [synthetic_weighted_avg],\n",
    "                                 'Average Difference': [weighted_avg_diff],\n",
    "                                 'Empirical Median': [empirical_median],\n",
    "                                 'Synthetic Median': [synthetic_median],\n",
    "                                 'Median Difference': [median_diff],\n",
    "                                 'Empirical Variance': [empirical_variance],\n",
    "                                 'Synthetic Variance': [synthetic_variance],\n",
    "                                 'Variance Difference': [variance_diff],\n",
    "                                 'RMSE': [rmse]})\n",
    "    \n",
    "    # Concatenate the year's metrics with the existing results DataFrame\n",
    "    results_df = pd.concat([results_df, year_metrics], ignore_index=True)\n",
    "\n",
    "# Read the existing metrics_simple.csv file\n",
    "existing_metrics = pd.read_csv('metrics_simple.csv')\n",
    "\n",
    "# Delete the previous results for this metric, if they exist. Drop everything except the \"Year\" column\n",
    "if 'Empirical Average' in existing_metrics.columns:\n",
    "    existing_metrics = existing_metrics.drop(columns=['Empirical Average',\n",
    "                                                      'Synthetic Average',\n",
    "                                                      'Average Difference',\n",
    "                                                      'Empirical Median',\n",
    "                                                      'Synthetic Median',\n",
    "                                                      'Median Difference',\n",
    "                                                      'Empirical Variance',\n",
    "                                                      'Synthetic Variance',\n",
    "                                                      'Variance Difference',\n",
    "                                                      'RMSE'])\n",
    "\n",
    "\n",
    "# Merge the existing metrics with the new results based on the \"Year\" column\n",
    "merged_metrics = existing_metrics.merge(results_df, on='Year')\n",
    "\n",
    "# Save the merged metrics to the metrics_simple.csv file\n",
    "merged_metrics.to_csv('metrics_simple.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson, Spearman \n",
    "- Annual coefficients\n",
    "- Daily coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2012\n",
      "Annual Pearson: 0.3424633742580565\n",
      "Annual Spearman: 0.7844559392715036\n",
      "Year: 2013\n",
      "Annual Pearson: 0.5378072368361123\n",
      "Annual Spearman: 0.8119328185734058\n",
      "Year: 2014\n",
      "Annual Pearson: 0.42973033922453585\n",
      "Annual Spearman: 0.8212555556211188\n",
      "Year: 2015\n",
      "Annual Pearson: 0.3110957481792914\n",
      "Annual Spearman: 0.7949795689144594\n",
      "Year: 2016\n",
      "Annual Pearson: 0.6069158306861713\n",
      "Annual Spearman: 0.7871957326779776\n",
      "Year: 2017\n",
      "Annual Pearson: 0.5795466268809675\n",
      "Annual Spearman: 0.836005334053351\n",
      "Year: 2018\n",
      "Annual Pearson: 0.3010603400970494\n",
      "Annual Spearman: 0.8505877506483107\n",
      "Year: 2019\n",
      "Annual Pearson: 0.28528987191966876\n",
      "Annual Spearman: 0.8416145985911915\n",
      "Year: 2020\n",
      "Annual Pearson: 0.3811249889721622\n",
      "Annual Spearman: 0.7962274988498416\n",
      "Year: 2021\n",
      "Annual Pearson: 0.3020536600120838\n",
      "Annual Spearman: 0.8511453780835465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Define the range of years\n",
    "years = range(2012, 2022)\n",
    "\n",
    "# Create an empty list to store the correlation coefficients\n",
    "daily_coefficients = pd.DataFrame()\n",
    "annual_coefficients = pd.DataFrame()\n",
    "\n",
    "# Iterate over the years\n",
    "for year in years:\n",
    "    # Read the empirical prices\n",
    "    empirical_prices = pd.read_csv(f\"{year}prices_emp.csv\")\n",
    "    \n",
    "    # Read the synthetic prices\n",
    "    synthetic_prices = pd.read_csv(f\"{year}prices.csv\")\n",
    "    synthetic_prices['Time_Index'] = synthetic_prices.index + 1\n",
    "    \n",
    "    # Exclude the n highest prices from synthetic dataset, and the corresponding prices from the empirical dataset\n",
    "    n = 15\n",
    "    synthetic_prices_excluded = synthetic_prices.nsmallest(len(synthetic_prices) - n, \"1\")\n",
    "    # sort the synthetic prices by index\n",
    "    synthetic_prices_excluded = synthetic_prices_excluded.sort_values(by=['Time_Index'])\n",
    "    empirical_prices_excluded = empirical_prices.loc[empirical_prices.index.isin(synthetic_prices_excluded.index)]\n",
    "    \n",
    "    # Extract the price columns\n",
    "    empirical_price_column = empirical_prices_excluded[\"Price\"]\n",
    "    synthetic_price_column = synthetic_prices_excluded[\"1\"]\n",
    "    \n",
    "    # Compute the Pearson and Spearman correlation\n",
    "    pearson_annual, _ = pearsonr(empirical_price_column, synthetic_price_column)\n",
    "    spearman_annual, _ = spearmanr(empirical_price_column, synthetic_price_column)\n",
    "\n",
    "    step_size = 24\n",
    "    pearson_daily = []\n",
    "    spearman_daily = []\n",
    "    days = []\n",
    "    for i in range(0, len(empirical_price_column), step_size):\n",
    "        y1 = empirical_price_column.iloc[i:i+step_size]\n",
    "        y2 = synthetic_price_column.iloc[i:i+step_size]\n",
    "        p_corr, _ = pearsonr(y1, y2)\n",
    "        s_corr, _ = spearmanr(y1, y2)\n",
    "        pearson_daily.append(p_corr)\n",
    "        spearman_daily.append(s_corr)\n",
    "        days.append(i/24+1)\n",
    "    \n",
    "    # Concatenate the year's annual coefficients with the existing annual_coefficients DataFrame\n",
    "    annual_coefficients = pd.concat([annual_coefficients, pd.DataFrame({'Year': [year],\n",
    "                                                                        'Pearson annual': [pearson_annual],\n",
    "                                                                        'Spearman annual': [spearman_annual]})\n",
    "                                        ], ignore_index=True)\n",
    "    \n",
    "    # Add the daily pearson and spearman coefficients to the existing dataframe\n",
    "    if 'Day' in daily_coefficients.columns:\n",
    "        daily_coefficients = daily_coefficients.drop(columns=['Day'])\n",
    "    daily_coefficients[f'{year}Pearson daily'] = pearson_daily\n",
    "    daily_coefficients[f'{year}Spearman daily'] = spearman_daily\n",
    "    daily_coefficients['Day'] = days\n",
    "\n",
    "    print(f\"Year: {year}\")\n",
    "    print(f\"Annual Pearson: {pearson_annual}\")\n",
    "    print(f\"Annual Spearman: {spearman_annual}\")\n",
    "\n",
    "# Read the existing files\n",
    "existing_annual_coefficients = pd.read_csv('annual_coefficients.csv')\n",
    "existing_daily_coefficients = pd.read_csv('daily_coefficients.csv')\n",
    "\n",
    "# Delete the previous results, if they exist. Drop everything except the \"Year\" (or Day) column\n",
    "if 'Pearson annual' in existing_annual_coefficients.columns:\n",
    "    existing_annual_coefficients = existing_annual_coefficients.drop(columns=['Pearson annual',\n",
    "                                                                              'Spearman annual'])\n",
    "if '2012Pearson daily' in existing_daily_coefficients.columns:\n",
    "    for year in years:\n",
    "        existing_daily_coefficients = existing_daily_coefficients.drop(columns=[f'{year}Pearson daily',\n",
    "                                                                            f'{year}Spearman daily'])\n",
    "\n",
    "# Merge the existing results with the new results based on the \"Year\" (or Day) column\n",
    "merged_annual_coefficients = existing_annual_coefficients.merge(annual_coefficients, on='Year')\n",
    "merged_daily_coefficients = existing_daily_coefficients.merge(daily_coefficients, on='Day')\n",
    "# merged_spearman_coefficients = existing_spearman_coefficients.merge(spearman_coefficients, on='Day')\n",
    "\n",
    "# Save the merged coefficients to the files\n",
    "merged_annual_coefficients.to_csv('annual_coefficients.csv', index=False)\n",
    "merged_daily_coefficients.to_csv('daily_coefficients.csv', index=False)\n",
    "# merged_spearman_coefficients.to_csv('spearman_daily.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
